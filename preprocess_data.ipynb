{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1DkvqjjrvDfoaqL3gqOoglq_JdRWFd1M-","authorship_tag":"ABX9TyNSBoOndURh0dkuJtSOUfvi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"im8Eof_BPpG3","executionInfo":{"status":"ok","timestamp":1701056940867,"user_tz":300,"elapsed":257,"user":{"displayName":"Liuyun Xu","userId":"17081058733007306017"}}},"outputs":[],"source":["import nibabel as nib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def extract_data(fp):\n","    '''\n","    Input: file path to ds000105_R2.0.2_raw folder\n","    Output: x_train, y_train, x_test, y_test\n","    object0: scissor\n","    object1: shoe\n","    9 pictures for each run each object\n","    '''\n","    pic_num = 9  # number of pictures for each object each run\n","    offset = 2 # shift for response delay\n","    z_value = [27, 29, 31, 33, 35]\n","    x_data = np.zeros((40, 64, 5, 2*2*9*12)) # (x, y, z, number of pictures)  432 = 2*2*9*12\n","    y_data = np.zeros(2*2*9*12)\n","    x_train = np.zeros((40, 64, 5, 2*2*9*11))\n","    y_train = np.zeros(2*2*9*11)\n","    x_test = np.zeros((40, 64, 5, 2*2*9*1))\n","    y_test = np.zeros(2*2*9*1)\n","    # object location for 12 runs\n","    filter = np.array([[5, 0, 48, 0],   # 12, 120\n","                        [63, 0, 34, 0],  # 156, 84\n","                        [34, 0, 77, 0],   # 84, 192\n","                        [106, 0, 5, 0],   # 264, 12\n","                        [20, 0, 77, 0],   # 48, 192\n","                        [106, 0, 48, 0],   # 264, 120\n","                        [34, 0, 48, 0],   # 84, 120\n","                        [34, 0, 48, 0],   # 84, 120\n","                        [106, 0, 77, 0],   # 264, 192\n","                        [63, 0, 92, 0],   # 156, 228\n","                        [106, 0, 92, 0],   # 264, 156\n","                        [106, 0, 77, 0], # 264, 192\n","                        # sub2\n","                        [5, 0, 48, 0],   # 12, 120\n","                        [34, 0, 48, 0],  # 84, 120\n","                        [106, 0, 77, 0],   # 264, 192\n","                        [106, 0, 5, 0],   # 264, 12\n","                        [63, 0, 34, 0],   # 156, 84\n","                        [34, 0, 77, 0],   # 84, 192\n","                        [20, 0, 77, 0],   # 48, 192\n","                        [34, 0, 48, 0],   # 84, 120\n","                        [63, 0, 92, 0],   # 156, 228\n","                        [106, 0, 48, 0],   # 264, 120\n","                        [106, 0, 92, 0],   # 264, 156\n","                        [106, 0, 77, 0]])  # 264, 192\n","\n","    # Create training data\n","    # Go through all the sub\n","    for s in range(1, 3):\n","\n","        # Go through all the run\n","        for x in range(1, 13):\n","\n","            if(x < 10):\n","                y = \"0\" + str(x)\n","            else:\n","                y = str(x)\n","            # File path\n","            file_path = fp + f'/sub-{s}/func/sub-{s}_task-objectviewing_run-{y}_bold.nii.gz'\n","\n","            # Load the data\n","            image = nib.load(file_path)\n","            data = image.get_fdata()\n","\n","            # Get object start number\n","            obj0s, obj0e, obj1s, obj1e = filter[12*(s-1) + x-1, :]\n","            obj0s += offset\n","            obj1s += offset\n","            i = 0\n","\n","            # Go through all the slice\n","            for z in z_value:\n","                x_data[:, :, i, 216*(s-1) + 2*pic_num*(x-1) : 216*(s-1) + 2*pic_num*(x-1)+pic_num] = data[:, :, z, obj0s : obj0s+pic_num]\n","                y_data[216*(s-1) + 2*pic_num*(x-1) : 216*(s-1) + 2*pic_num*(x-1)+pic_num] = 0\n","                x_data[:, :, i, 216*(s-1) + 2*pic_num*(x-1)+pic_num : 216*(s-1) + 2*pic_num*(x-1)+2*pic_num] = data[:, :, z, obj1s : obj1s+pic_num]\n","                y_data[216*(s-1) + 2*pic_num*(x-1)+pic_num : 216*(s-1) + 2*pic_num*(x-1)+2*pic_num] = 1\n","                i += 1\n","\n","    # Shuffle the data set\n","    # Generate a permutation of indices\n","    perm = np.random.permutation(2*2*9*12)\n","    # Apply the permutation to both arrays\n","    x_data = x_data[:, :, :, perm]\n","    y_data = y_data[perm]\n","\n","    # take 11/12 as training set\n","    x_train = x_data[:, :, :, 0: 397]\n","    y_train = y_data[0: 397]\n","    # take 1/12 as testing set\n","    x_test = x_data[:, :, :, 397: 433]\n","    y_test = y_data[397: 433]\n","\n","    return x_train, y_train, x_test, y_test\n","\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KIwhrd438yx","executionInfo":{"status":"ok","timestamp":1701059889197,"user_tz":300,"elapsed":1013,"user":{"displayName":"Liuyun Xu","userId":"17081058733007306017"}},"outputId":"c842dace-a908-48e1-e052-ae9ddcf4bff1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["x_train, y_train, x_test, y_test = extract_data('drive/MyDrive/Colab Notebooks/ds000105_R2.0.2_raw')\n","#print(y_train)\n","print(np.count_nonzero(y_train))\n","print(np.count_nonzero(y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd1kbZfRQ4u8","executionInfo":{"status":"ok","timestamp":1701059976913,"user_tz":300,"elapsed":45956,"user":{"displayName":"Liuyun Xu","userId":"17081058733007306017"}},"outputId":"5563715b-b73f-4502-f2ec-e269d1730aa7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["200\n","16\n"]}]},{"cell_type":"code","source":["#reshape and normalize data\n","x_train2=x_train.reshape(40*64*5, x_train.shape[3])\n","x_test2=x_test.reshape(40*64*5, x_test.shape[3])\n","x_train2=x_train2.T\n","x_test2=x_test2.T\n","mean_train = np.mean(x_train2, axis=0)\n","std_train = np.std(x_train2, axis=0)\n","x_train_norm = (x_train2 - mean_train) / std_train\n","x_test_norm = (x_test2 - mean_train) / std_train"],"metadata":{"id":"VDRIkNNfE_dC","executionInfo":{"status":"ok","timestamp":1701060161045,"user_tz":300,"elapsed":4,"user":{"displayName":"Liuyun Xu","userId":"17081058733007306017"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["## denoise: Gaussian smoothing\n","import cv2\n","x_train_gs = cv2.GaussianBlur(x_train_norm, (5, 5), 0)"],"metadata":{"id":"sElJC0nRFVds","executionInfo":{"status":"ok","timestamp":1701060309054,"user_tz":300,"elapsed":3,"user":{"displayName":"Liuyun Xu","userId":"17081058733007306017"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["## PCA reduce order\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","\n","def pca_reduce(x_train,num_components): # Set the number of components you want to keep\n","  # Standardize the data\n","  scaler = StandardScaler()\n","  X_train_scaled = scaler.fit_transform(x_train)\n","\n","  # Perform PCA\n","  pca = PCA(n_components=num_components)\n","  X_train_pca = pca.fit_transform(X_train_scaled)\n","\n","  return X_train_pca\n","\n","X_train_pca=pca_reduce(x_train_gs,200)"],"metadata":{"id":"JkkdzQuVHDwC","executionInfo":{"status":"ok","timestamp":1701060905291,"user_tz":300,"elapsed":5606,"user":{"displayName":"Liuyun Xu","userId":"17081058733007306017"}}},"execution_count":24,"outputs":[]}]}